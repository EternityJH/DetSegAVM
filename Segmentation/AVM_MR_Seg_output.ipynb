{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "#from torchsampler import ImbalancedDatasetSampler\n",
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print('cuda available: '+ str(torch.cuda.is_available()))\n",
    "#from skimage.morphology import disk, binary_dilation\n",
    "\n",
    "from models_avm import NestedUNet\n",
    "from loss_fun_avm import compute_per_channel_dice\n",
    "from tra_val_avm import inference_out\n",
    "from data_loader_avm import Dataset_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data list here\n",
    "# The files for only segmentation inference should be those slices with the bAVM.\n",
    "\n",
    "path_tra1 = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forUNetpp\\1_tra\\1' #mod\n",
    "list_tra1 = os.listdir(path_tra1)\n",
    "for i in range(len(list_tra1)):\n",
    "    list_tra1[i] = path_tra1+'/'+list_tra1[i]\n",
    "    \n",
    "list_tra = list_tra1\n",
    "    \n",
    "path_val1 = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forUNetpp\\2_val\\1' #mod\n",
    "list_val1 = os.listdir(path_val1)\n",
    "for i in range(len(list_val1)):\n",
    "    list_val1[i] = path_val1+'/'+list_val1[i]\n",
    "    \n",
    "list_val = list_val1\n",
    "\n",
    "path_ts1 = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forUNetpp\\3_ts\\1' #mod\n",
    "list_ts1 = os.listdir(path_ts1)\n",
    "for i in range(len(list_ts1)):\n",
    "    list_ts1[i] = path_ts1+'/'+list_ts1[i]\n",
    "    \n",
    "list_ts = list_ts1\n",
    "\n",
    "path_tra_lab_txt = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forYOLOv5\\labels\\1_tra' #mod\n",
    "path_val_lab_txt = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forYOLOv5\\labels\\2_val' #mod\n",
    "path_ts_lab_txt = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forYOLOv5\\labels\\3_ts' #mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and load trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call model cuda for gpu\n",
    "#model = UNet(norm_method='group').cuda()\n",
    "model = NestedUNet(norm_method='group').cuda() #mod\n",
    "\n",
    "# load trained model\n",
    "PATH = r'C:\\Users\\USER\\Desktop\\Segmentation\\Models\\unetpp\\Models\\Seg_dia10\\train\\exp1\\best_val.tar' #mod\n",
    "own_state = torch.load(PATH)\n",
    "model.load_state_dict(own_state)\n",
    "model.eval();\n",
    "\n",
    "# score function\n",
    "score = [compute_per_channel_dice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   100/ 3476 batches | ms/batch 7854.00 | \n",
      "|   200/ 3476 batches | ms/batch 7803.00 | \n",
      "|   300/ 3476 batches | ms/batch 6872.00 | \n",
      "|   400/ 3476 batches | ms/batch 7370.00 | \n",
      "|   500/ 3476 batches | ms/batch 7153.59 | \n",
      "|   600/ 3476 batches | ms/batch 8028.00 | \n",
      "|   700/ 3476 batches | ms/batch 9250.00 | \n",
      "|   800/ 3476 batches | ms/batch 9120.00 | \n",
      "|   900/ 3476 batches | ms/batch 6818.00 | \n",
      "|  1000/ 3476 batches | ms/batch 5930.00 | \n",
      "|  1100/ 3476 batches | ms/batch 8008.00 | \n",
      "|  1200/ 3476 batches | ms/batch 6846.00 | \n",
      "|  1300/ 3476 batches | ms/batch 7402.10 | \n",
      "|  1400/ 3476 batches | ms/batch 7897.00 | \n",
      "|  1500/ 3476 batches | ms/batch 6365.00 | \n",
      "|  1600/ 3476 batches | ms/batch 8405.00 | \n",
      "|  1700/ 3476 batches | ms/batch 7527.00 | \n",
      "|  1800/ 3476 batches | ms/batch 7019.00 | \n",
      "|  1900/ 3476 batches | ms/batch 6136.00 | \n",
      "|  2000/ 3476 batches | ms/batch 9316.00 | \n",
      "|  2100/ 3476 batches | ms/batch 7119.56 | \n",
      "|  2200/ 3476 batches | ms/batch 7797.00 | \n",
      "|  2300/ 3476 batches | ms/batch 6764.00 | \n",
      "|  2400/ 3476 batches | ms/batch 8312.00 | \n",
      "|  2500/ 3476 batches | ms/batch 7735.00 | \n",
      "|  2600/ 3476 batches | ms/batch 7769.00 | \n",
      "|  2700/ 3476 batches | ms/batch 6607.00 | \n",
      "|  2800/ 3476 batches | ms/batch 6995.00 | \n",
      "|  2900/ 3476 batches | ms/batch 8369.57 | \n",
      "|  3000/ 3476 batches | ms/batch 7899.00 | \n",
      "|  3100/ 3476 batches | ms/batch 7582.00 | \n",
      "|  3200/ 3476 batches | ms/batch 8546.00 | \n",
      "|  3300/ 3476 batches | ms/batch 8636.00 | \n",
      "|  3400/ 3476 batches | ms/batch 9704.00 | \n",
      "|  3476/ 3476 batches | ms/batch 6833.00 | \n",
      "|   100/  472 batches | ms/batch 7169.00 | \n",
      "|   200/  472 batches | ms/batch 7752.56 | \n",
      "|   300/  472 batches | ms/batch 9835.00 | \n",
      "|   400/  472 batches | ms/batch 7213.00 | \n",
      "|   472/  472 batches | ms/batch 4892.00 | \n",
      "|   100/  340 batches | ms/batch 6293.00 | \n",
      "|   200/  340 batches | ms/batch 7279.00 | \n",
      "|   300/  340 batches | ms/batch 7716.00 | \n",
      "|   340/  340 batches | ms/batch 2709.00 | \n"
     ]
    }
   ],
   "source": [
    "# Log and results saving directory\n",
    "path = r'C:\\Users\\USER\\Desktop\\Segmentation\\Results\\1_Results_unet\\dia10' #mod\n",
    "\n",
    "dia_factor = [0,5,10,20,30,40,50]\n",
    "\n",
    "#i = 0\n",
    "for i in range(len(dia_factor)):\n",
    "    # Data loader\n",
    "    tra_data = Dataset_out(list_tra,path_tra_lab_txt,dia_factor[i])\n",
    "    tra_loader_out = torch.utils.data.DataLoader(\n",
    "        dataset = tra_data,           \n",
    "        batch_size = 1,                 \n",
    "        shuffle = False)\n",
    "    val_data = Dataset_out(list_val,path_val_lab_txt,dia_factor[i])\n",
    "    val_loader_out = torch.utils.data.DataLoader(\n",
    "        dataset = val_data,           \n",
    "        batch_size = 1,                 \n",
    "        shuffle = False)\n",
    "    ts_data = Dataset_out(list_ts,path_ts_lab_txt,dia_factor[i])\n",
    "    ts_loader_out = torch.utils.data.DataLoader(\n",
    "        dataset = ts_data,           \n",
    "        batch_size = 1,                 \n",
    "        shuffle = False)\n",
    "\n",
    "    path_sav_tra = path+'\\\\r'+str(dia_factor[i])+'\\\\1_tra'\n",
    "    if os.path.isdir(path_sav_tra)==False:\n",
    "        os.mkdir(path_sav_tra)\n",
    "    path_sav_val = path+'\\\\r'+str(dia_factor[i])+'\\\\2_val'\n",
    "    if os.path.isdir(path_sav_val)==False:\n",
    "        os.mkdir(path_sav_val)\n",
    "    path_sav_ts = path+'\\\\r'+str(dia_factor[i])+'\\\\3_ts'\n",
    "    if os.path.isdir(path_sav_ts)==False:\n",
    "        os.mkdir(path_sav_ts)\n",
    "\n",
    "    inference_out(path_sav_tra,model,score,tra_loader_out)\n",
    "    inference_out(path_sav_val,model,score,val_loader_out)\n",
    "    inference_out(path_sav_ts,model,score,ts_loader_out)\n",
    "\n",
    "\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log ^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
