{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available: True\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kornia'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#from skimage.morphology import disk, binary_dilation\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels_avm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NestedUNet\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloss_fun_avm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_per_channel_dice, DiceLoss, FocalLoss\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtra_val_avm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, validation\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_loader_avm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/AVM_tcvgh_code/unetpp/loss_fun_avm.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkornia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mone_hot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m one_hot\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kornia'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "#from torchsampler import ImbalancedDatasetSampler\n",
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print('cuda available: '+ str(torch.cuda.is_available()))\n",
    "#from skimage.morphology import disk, binary_dilation\n",
    "\n",
    "from models_avm import NestedUNet\n",
    "from loss_fun_avm import compute_per_channel_dice, DiceLoss, FocalLoss\n",
    "from tra_val_avm import train, validation\n",
    "from data_loader_avm import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tra1 = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forUNetpp\\1_tra\\1'\n",
    "list_tra1 = os.listdir(path_tra1)\n",
    "for i in range(len(list_tra1)):\n",
    "    list_tra1[i] = path_tra1+'/'+list_tra1[i]\n",
    "    \n",
    "list_tra = list_tra1\n",
    "    \n",
    "path_val1 = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forUNetpp\\2_val\\1'\n",
    "list_val1 = os.listdir(path_val1)\n",
    "for i in range(len(list_val1)):\n",
    "    list_val1[i] = path_val1+'/'+list_val1[i]\n",
    "    \n",
    "list_val = list_val1\n",
    "\n",
    "path_ts1 = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forUNetpp\\3_ts\\1'\n",
    "list_ts1 = os.listdir(path_ts1)\n",
    "for i in range(len(list_ts1)):\n",
    "    list_ts1[i] = path_ts1+'/'+list_ts1[i]\n",
    "    \n",
    "list_ts = list_ts1\n",
    "\n",
    "path_tra_lab_txt = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forYOLOv5\\labels\\1_tra'\n",
    "path_val_lab_txt = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forYOLOv5\\labels\\2_val'\n",
    "path_ts_lab_txt = r'E:\\AVM_Project_TCVGH\\Datasets\\prc\\6_Datasets_for_model_fin2D\\forYOLOv5\\labels\\3_ts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(list_tra,path_tra_lab_txt,rand_dilate=False)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, \n",
    "    batch_size = 8,\n",
    "    shuffle = True,   \n",
    ")\n",
    "\n",
    "val_data = Dataset(list_val,path_val_lab_txt,rand_dilate=False)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset = val_data,           \n",
    "    batch_size = 4,                 \n",
    "    shuffle = False,              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call model cuda for gpu\n",
    "model = NestedUNet().cuda()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.95)\n",
    "\n",
    "# loss function\n",
    "kwargs = {\"alpha\": 0.5, \"gamma\": 3, \"reduction\": 'mean'}\n",
    "criterion_FL = FocalLoss(**kwargs)\n",
    "criterion_DICE = DiceLoss()\n",
    "loss = [criterion_FL,criterion_DICE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     12\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m          \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m          \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m89\u001b[39m)\n\u001b[0;32m     21\u001b[0m     vallossnew \u001b[38;5;241m=\u001b[39m validation(path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m     22\u001b[0m           model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     23\u001b[0m           loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m     24\u001b[0m           dataloader\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[0;32m     25\u001b[0m           epoch\u001b[38;5;241m=\u001b[39mepoch)\n",
      "File \u001b[1;32mE:\\AVM_Project_TCVGH\\Codes\\python_code\\unetpp_segmentation\\tra_val_avm.py:46\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# loss calculation\u001b[39;00m\n\u001b[0;32m     44\u001b[0m loss_fl \u001b[38;5;241m=\u001b[39m loss[\u001b[38;5;241m0\u001b[39m](output, batch_y)\n\u001b[0;32m     45\u001b[0m loss_dice \u001b[38;5;241m=\u001b[39m loss[\u001b[38;5;241m1\u001b[39m](\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mmake_one_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcuda(),\n\u001b[0;32m     47\u001b[0m     make_one_hot(batch_y\u001b[38;5;241m.\u001b[39mreshape(batch_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m,batch_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],batch_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]),\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# backward   \u001b[39;00m\n\u001b[0;32m     50\u001b[0m loss_fl\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mE:\\AVM_Project_TCVGH\\Codes\\python_code\\unetpp_segmentation\\loss_fun_avm.py:190\u001b[0m, in \u001b[0;36mmake_one_hot\u001b[1;34m(input, num_classes)\u001b[0m\n\u001b[0;32m    188\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(shape)\n\u001b[0;32m    189\u001b[0m result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(shape)\n\u001b[1;32m--> 190\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mscatter_(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create Directory\n",
    "path = r'E:\\AVM_Project_TCVGH\\Experiments\\20220415_unetpp\\Models_no_rand_dia_bx'\n",
    "\n",
    "if os.path.isdir(path)==False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "# Train the Model\n",
    "epochs = 500 # The number of epochs\n",
    "\n",
    "valloss = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(path=path,\n",
    "          model=model,\n",
    "          loss=loss,\n",
    "          optimizer=optimizer,\n",
    "          dataloader=train_loader,\n",
    "          epoch=epoch,\n",
    "          scheduler=scheduler)\n",
    "    print('-' * 89)\n",
    "    vallossnew = validation(path=path,\n",
    "          model=model,\n",
    "          loss=loss,\n",
    "          dataloader=val_loader,\n",
    "          epoch=epoch)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time)))\n",
    "    print('-' * 89)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    f2 = open(path + '/model_info.txt', 'a')\n",
    "    if vallossnew<valloss or epoch ==1: \n",
    "        fname = path + '/best_val'  + '.tar'\n",
    "        torch.save(model.state_dict(), fname)\n",
    "        valloss = vallossnew\n",
    "        f2.write('| best_val | epoch {:3d}| '.format(epoch)+'\\r\\n')        \n",
    "    f2.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log ^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
